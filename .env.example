# AI Configuration for Skill Index Generator
# Part of Portable Skill Activator by Gabi @ Booplex (booplex.com)
#
# Copy this to .env and fill in your values
#
# The AI only runs when you generate the index - not on every message.
# Pick whatever provider you have access to. They all work.

# =============================================================================
# REQUIRED: Pick Your Provider
# =============================================================================

# Options: claude, openai, anthropic, ollama, openrouter, custom
#
# "claude" = Uses Claude Code CLI (no API key needed!)
#            Piggybacks on your existing Claude Code installation
#
AI_PROVIDER=claude

# Your API key (not needed for "claude" or "ollama" providers)
AI_API_KEY=

# Which model to use
# - For "claude" provider: haiku, sonnet, opus (default: haiku - fast & cheap)
# - For others: gpt-4o-mini, claude-sonnet-4-20250514, llama3, etc.
AI_MODEL=haiku

# =============================================================================
# OPTIONAL: Custom Endpoint
# =============================================================================

# Only set this if you're using a proxy, self-hosted, or non-standard endpoint
# Leave commented out to use provider defaults
#
# AI_BASE_URL=https://your-endpoint.com/v1

# =============================================================================
# OPTIONAL: Generation Tuning
# =============================================================================

# Max tokens for AI response (2000 is plenty for keyword extraction)
AI_MAX_TOKENS=2000

# Temperature: 0.0 = deterministic, 1.0 = creative
# Lower is better for consistent keyword extraction
AI_TEMPERATURE=0.3

# How long to wait before timing out (seconds)
AI_TIMEOUT=60

# =============================================================================
# OPTIONAL: Fallback & Retry
# =============================================================================

# If main model fails, try these (comma-separated)
# For claude provider: haiku,sonnet
# For openai: gpt-4o-mini,gpt-3.5-turbo
AI_FALLBACK_MODELS=

# How many times to retry before giving up
AI_MAX_RETRIES=3

# Seconds between retries
AI_RETRY_DELAY=2.0

# =============================================================================
# OPTIONAL: Rate Limiting
# =============================================================================

# Max requests per minute (helps avoid API rate limits)
AI_RATE_LIMIT_RPM=20

# Minimum delay between requests (seconds)
AI_RATE_LIMIT_DELAY=0.5

# =============================================================================
# OPTIONAL: Language
# =============================================================================

# Which languages to extract keywords in (comma-separated)
# Default is english. Add more if your skills target other languages.
AI_LANGUAGES=english

# =============================================================================
# Quick Copy-Paste Configs
# =============================================================================
# Uncomment the section that matches your setup

# --- Claude Code CLI (RECOMMENDED - no API key needed!) ---
# AI_PROVIDER=claude
# AI_MODEL=haiku
# (or sonnet/opus for better quality)

# --- OpenAI ---
# AI_PROVIDER=openai
# AI_API_KEY=sk-...
# AI_MODEL=gpt-4o-mini

# --- Anthropic ---
# AI_PROVIDER=anthropic
# AI_API_KEY=sk-ant-...
# AI_MODEL=claude-sonnet-4-20250514

# --- Ollama (local, free) ---
# AI_PROVIDER=ollama
# AI_MODEL=llama3
# AI_BASE_URL=http://localhost:11434

# --- OpenRouter (access to many models) ---
# AI_PROVIDER=openrouter
# AI_API_KEY=sk-or-...
# AI_MODEL=anthropic/claude-3-opus

# --- LM Studio (local) ---
# AI_PROVIDER=custom
# AI_MODEL=local-model
# AI_BASE_URL=http://localhost:1234/v1

# --- Any OpenAI-compatible API ---
# AI_PROVIDER=custom
# AI_API_KEY=your-key
# AI_MODEL=your-model
# AI_BASE_URL=https://your-endpoint.com/v1
